# Итоговый проект

Теперь пришло время перейти от теории к практике и заняться настоящими делами! Мы подготовили для вас удивительный проект с реальным применением – интеграцию нашего редактора кода в обучающую систему кое-какого онлайн-университета.

## Описание

У нас есть корпоративный клиент - крупный онлайн-университет, которому мы интегрировали наш редактор кода внутрь его обучающей системы (**ЛМС**). Далее будем называть наш редактор кода **грейдером** (от слова `grade`, т.к. мы проверяем решения студентов и отправляем клиенту баллы). 

Каждый день тысячи студентов этого университета решают разнообразные задачи в нашем редакторе. И когда они отправляют свои решения, запросы улетают к нам на сервер. Мы обрабатываем эти данные и возвращаем ответы, которые не только позволяют выставить оценку студентам, но и содержат важную информацию об их успехах и прогрессе.

Естественно, вся эта ценная информация сохраняется у нас в базе данных. 🙂 Мы записываем, кто из студентов решал конкретные задачи, какой код они писали, когда была произведена попытка решения, и была ли она успешной. Эти данные помогают университету оценить образовательный процесс, дать обратную связь студентам и определить наиболее эффективные методы обучения.

Теперь представьте, вы стали частью команды аналитики в этом самом онлайн-университете. Да что там частью, судя по предстоящему проекту - как минимум сеньором! 😃 И перед вами стоит задача - научиться забирать от нас данные, собирать их в собственную базу и далее их обрабатывать. Вы столкнетесь с вызовами, связанными с обработкой больших объемов данных, валидацией информации и грамотной структуризацией базы данных.

>>>
Но глаза боятся, а руки делают!
>>>

Мы со своей стороны сделали API, в котором доступен один endpoint (URL-адрес), на который можно отправить запрос, указать различные параметры и получить данные из нашей базы об использовании студентами грейдера. Все, что вам нужно сделать, это научить свой скрипт обращаться к этому API и получать необходимую информацию.

Приступим?

### Подробнее

Глобально, ваша задача на итоговый проект - написать скрипт, в котором:

* Будет происходить обращение к нашему API для получения данных
* Данные будут обрабатываться и готовиться к загрузке в базу данных
* Обработанные данные будут загружаться в локальную базу PostgreSQL, которую вы развернули на своем компьютере или в облаке
* Во время обработки будет сохраняться лог работы скрипта с отлавливанием всех ошибок и выводом промежуточных стадий (например, скачивание началось / скачивание завершилось / заполнение базы началось и т.д., с трекингом времени). Лог нужно сохранять в текстовый файл. Файл нужно именовать в соответствии с текущей датой. Если в папке с логами уже есть другие логи - их необходимо удалять, оставляем только логи за последние 3 дня.

**Как работать с API?**

Для взаимодействия с нашим API и получения данных, используйте уже знакомую вам библиотеку `requests`. Вам понадобится URL-адрес и выглядеть это будет примерно так:

```python
api_url = "https://b2b.itresume.ru/api/statistics"
```

>>>
Причем, придется определить еще несколько дополнительных параметров:

* `client` - Skillfactory (регистр **важен**)
* `client_key` - M2MGWS (регистр **важен**)
* `start` - дата-время начала в формате `2023-04-01 12:46:47.860798`` (**время на сервере в нулевом часовом поясе**)
* `end` - аналогично дата окончания
>>>

И дальше, уже знакомый вам, `requests.get()`. Вот тут вы получите, возможно, пугающий ответ, поэтому подготовим вас. 

Пример ответа от API:

```
[
    {
        "lti_user_id": "3583bf109f8b458e13ae1ac9d85c396a",
        "passback_params": "{'oauth_consumer_key': '', 'lis_result_sourcedid': 'course-v1:SkillFactory+DST-3.0+28FEB2021:lms.skillfactory.ru-ca3ecf8e5f284c329eb7bd529e1a9f7e:3583bf109f8b458e13ae1ac9d85c396a', 'lis_outcome_service_url': 'https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DST-3.0+28FEB2021/xblock/block-v1:SkillFactory+DST-3.0+28FEB2021+type@lti+block@ca3ecf8e5f284c329eb7bd529e1a9f7e/handler_noauth/grade_handler'}",
        "is_correct": null,
        "attempt_type": "run",
        "created_at": "2023-05-31 09:16:11.313646"
    },
    {
        "lti_user_id": "ab6ddeb7654ab35d44434d8db629bd01",
        "passback_params": "{'oauth_consumer_key': '', 'lis_result_sourcedid': 'course-v1:SkillFactory+DSPR-2.0+14JULY2021:lms.skillfactory.ru-0cf38fe58c764865bae254da886e119d:ab6ddeb7654ab35d44434d8db629bd01', 'lis_outcome_service_url': 'https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/xblock/block-v1:SkillFactory+DSPR-2.0+14JULY2021+type@lti+block@0cf38fe58c764865bae254da886e119d/handler_noauth/grade_handler'}",
        "is_correct": null,
        "attempt_type": "run",
        "created_at": "2023-05-31 09:16:30.117858"
    }
]
```

В целом, частично понятная структура, но ох уж этот `passback_params`. Он представлен в специфическом виде и вам придется немного с ним поработать. Более того, некоторые поля в нем могут вообще отсутствовать, а некоторые вообще быть лишними (вспоминаем кейс с чеками 😄). В общем вам придется привести его к адеватному виду.

**Адекватный вид**

Поскольку все эти данные мы с вами должны сохранить в локальную базу - определим её структуру.

* `user_id` - строковый айди пользователя
* `oauth_consumer_key` - уникальный токен клиента
* `lis_result_sourcedid` - ссылка на блок, в котором находится задача в ЛМС
* `lis_outcome_service_url` - `URL` адрес в ЛМС, куда мы шлем оценку
* `is_correct` - была ли попытка верной (`null`, если это `run`)
* `attempt_type` - ран или сабмит
* `created_at` - дата и время попытки

Все эти данные можно увидеть в примере ответа от API выше. Если не обращать внимание на то, что необходимые нам `oauth_consumer_key`, `lis_result_sourcedid` и `lis_outcome_service_url` спрятаны в `passback_params` - все выглядит даже легко. Но придется как-то это разобрать, и не забудьте провалидировать данные (чтобы не пропустить не тот тип данных или не подходящее значение). Если что-то не так - запись можно пропустить и занести информацию в лог.

Следующим шагом будет загрузка предобработанных данных в вашу локальную базу PostgreSQL. Вы можете развернуть её на своей машине или в облаке. Думаем, тут дополнительные пояснения не нужны, импортируете `psycopg2`, а все остальное - мы уже делали в предыдущих уроках или видео.

### Логирование

А вот теперь подходим к самому интересному - скрипт получается большой и долгий, надо бы для всего этого процесса организовать лог. Это помогло бы отлавливать ошибки, информировать о промежуточных стадиях и тд.

Грубо говоря, когда начинается скачивание данных, должна произвестись соответствующая `INFO` запись, когда скачивание завершается - тоже, ошибка доступа к API - запись `ERROR` со `status_code`, начали заполнять базу - запись. И все это обязательно с временной меткой (так уж положено 🙂).

Сохранить все это вы можете в текстовый файл, и назвать в соответствии с текущей датой. Причем, если в папке с логами уже есть другие логи - их необходимо удалить, оставив только логи за последние 3 дня.

## Задание со звездочкой №1

Кое-кто из нашей команды (не будем называть имен), предлагая идеи для вашего итогового проекта, вспомнил "**Они же работали с Google Sheets! Давайте добавим и его**". "**А давайте!**" - сказали мы, поэтому ловите.

Добавьте в ваш скрипт код, который в конце будет агрегировать данные за день. Например:

* сколько попыток было совершено;
* сколько успешных попыток было из всех совершенных;
* количество уникальных юзеров;
* можете добавить все, на что у вас хватит фантазии.

И загрузите это все в табличку в `Google Sheets` (чтобы начальник мог все посмотреть без доступа к БД 🙂). Загружать из `Google Sheets` вы уже научились, теперь разберитесь как загрузить в них данные. Механика будет практически та же самая, но придется немного повозиться с `credentials` и аутентификацией. 

## Задание с двумя звездочками 

Продолжаем работать на комфорт всей команды - давайте настроим оповещения на почту. Чтобы все знали, что вы свою работу сделали на отлично.


